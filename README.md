# ğŸš€ Production Pipeline - Complete ML System

## ğŸ“ Directory Structure

```
production_pipeline/
â”œâ”€â”€ ğŸ¯ run_complete_ml_pipeline.py          # MAIN ORCHESTRATOR
â”œâ”€â”€ ğŸ”§ export_ml_features.py               # Enhanced SQL with historical features
â”œâ”€â”€ ğŸ”§ merge_financial_features.py         # Financial preprocessing
â”œâ”€â”€ ğŸ¯ run_ml_training.py                  # ML training
â”œâ”€â”€ ğŸ“¦ requirements.txt                    # Dependencies
â”œâ”€â”€ ğŸ“– README.md                           # This documentation
â”‚
â”œâ”€â”€ ğŸ“Š data/                               # ALL DATA HERE
â”‚   â”œâ”€â”€ sentiment_system.duckdb           # Main database (225MB)
â”‚   â”œâ”€â”€ lancedb_store/                    # Vector embeddings
â”‚   â””â”€â”€ storage_lancedb_store/            # Additional vector storage
â”‚
â”œâ”€â”€ ğŸ¤– agents/                             # LLM AGENTS
â”‚   â”œâ”€â”€ fundamentals/enhanced_fundamentals_agent_duckdb.py
â”‚   â”œâ”€â”€ news/enhanced_news_agent_duckdb.py
â”‚   â”œâ”€â”€ userposts/enhanced_userposts_agent_complete.py
â”‚   â””â”€â”€ analyst_recommendations/enhanced_analyst_recommendations_agent_duckdb.py
â”‚
â”œâ”€â”€ ğŸ° embeddings/                         # VECTOR GENERATION
â”‚   â”œâ”€â”€ embed_fundamentals_duckdb.py
â”‚   â”œâ”€â”€ embed_news_duckdb.py
â”‚   â”œâ”€â”€ embed_userposts_duckdb.py
â”‚   â””â”€â”€ embed_analyst_recommendations_duckdb.py
â”‚
â”œâ”€â”€ ğŸ”§ core/                               # FEATURE MERGING
â”‚   â”œâ”€â”€ ml_feature_merger.py
â”‚   â””â”€â”€ financial_features.py
â”‚
â””â”€â”€ ğŸ› ï¸ tools/                              # UTILITIES
    â”œâ”€â”€ setup_validator_duckdb.py
    â””â”€â”€ cli_extract_*.py
```

## ğŸš€ Quick Start

### **New Data Processing Workflow**

```bash
# Navigate to production pipeline
cd production_pipeline/

# Option 1: Complete Pipeline (Recommended)
python run_complete_ml_pipeline.py --mode training

# Option 2: Step-by-Step Control
# 1. Create embeddings for new data
python embeddings/embed_news_duckdb.py --db-path data/sentiment_system.duckdb --lancedb-dir data/lancedb_store

# 2. Run complete pipeline
python run_complete_ml_pipeline.py --mode training
```

### **Programmatic Usage**

```python
from run_complete_ml_pipeline import CompletePipeline

# Initialize pipeline
pipeline = CompletePipeline()

# Run training with setup IDs
setup_ids = ['SETUP_001', 'SETUP_002', 'SETUP_003']
results = pipeline.run_complete_pipeline(setup_ids, mode='training')

# Run prediction
results = pipeline.run_complete_pipeline(setup_ids, mode='prediction')
```

### **Enhanced Features Usage**

```python
from export_ml_features import export_training_features, export_prediction_features
from merge_financial_features import merge_financial_features

# Extract enhanced features with historical analysis
export_training_features(
    db_path="data/sentiment_system.duckdb", 
    setup_ids=setup_ids,
    output_dir="output/"
)

# Merge financial features
merge_financial_features(
    db_path="data/sentiment_system.duckdb",
    setup_ids=setup_ids,
    mode='training'
)
```

## ğŸ¯ Enhanced Historical Features

This production pipeline includes comprehensive historical financial analysis:

### **Multi-Year Growth Features**
- YoY growth rates for revenue, operating income, net income, EBITDA (1-3 years)
- Growth consistency and volatility metrics
- Growth acceleration/deceleration indicators

### **Rolling Statistics**
- 3-year moving averages for key financial metrics
- Historical margin analysis (operating margin, net margin)
- Leverage evolution tracking

### **Trend Indicators**
- Consecutive growth years tracking
- Financial health evolution
- Trend strength scoring

## ğŸ”„ Data Flow

```
ğŸ“Š NEW DATA (DuckDB) 
    â†“
ğŸ° EMBEDDINGS (LanceDB)
    â†“  
ğŸ¤– AGENTS (Feature Extraction)
    â†“
ğŸ”§ FEATURE MERGING (Enhanced Historical)
    â†“
ğŸ¯ ML TRAINING
```

## ğŸ“‹ System Requirements

- Python 3.8+
- DuckDB with financial data
- LanceDB for vector storage
- Dependencies in requirements.txt

## ğŸ‰ Benefits

1. **ğŸ  Self-Contained**: Everything in one directory
2. **ğŸ“Š Enhanced Features**: Historical financial analysis included
3. **ğŸš€ Simple Workflow**: One command handles everything
4. **ğŸ’¾ Co-located Data**: DuckDB and LanceDB together
5. **ğŸ”§ Production Ready**: Clean, organized, tested structure

## ğŸš¨ Usage Examples

### For New Financial Data
```bash
cd production_pipeline/
python run_complete_ml_pipeline.py --mode training --setup-ids SETUP_001 SETUP_002
```

### For Prediction
```bash
cd production_pipeline/
python run_complete_ml_pipeline.py --mode prediction --setup-ids SETUP_003 SETUP_004
```

### Custom Database Path
```bash
cd production_pipeline/
python run_complete_ml_pipeline.py --mode training --db-path data/sentiment_system.duckdb --lancedb-dir data/lancedb_store
```

This production pipeline combines the best of both worlds: your proven original pipeline architecture with enhanced historical financial features, all organized in a clean, self-contained structure! ğŸ¯ 